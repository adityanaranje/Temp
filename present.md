ğŸ›¡ï¸ CodeGuard: Automated Intelligence for Code Integrity

ğŸš€ Hackathon Presentation Pitch

1. The Core Problem: The PR Bottleneck â³

Slow Velocity: Developers wait hours or days for human reviews.

Inconsistency: Different reviewers focus on different standards.

Security Risks: Human eyes often miss hardcoded secrets or subtle logic flaws.

Organization Rules: Enforcing "Company-only" rules (naming conventions, internal libs) is tedious.

2. Our Solution: CodeGuard ğŸ¦¾

An intelligent, automated PR review system that acts as the first line of defense.

Hybrid Analysis: Combines lightning-fast Static Rule Checking with deep LLM-powered reasoning.

Instant Feedback: Reviews are posted within seconds of a PR being opened.

Auto-Enforcement: Automatically approves or requests changes based on custom thresholds.

3. Key Features ğŸŒŸ

ğŸ” Rule Engine: Regex-based detection for hardcoded keys, debug statements, and naming violations.

ğŸ§  LLM Deep-Dive: Uses Groq (Llama 3) to analyze complex logic, edge cases, and security vulnerabilities.

ğŸ“Š Insights Dashboard: Real-time visibility into PR health, common violations, and team velocity.

ğŸ› ï¸ Hot-Swappable Rules: YAML-based configuration allows teams to update standards without code changes.

4. Technical Architecture ğŸ—ï¸

GitHub Webhook: Triggers on PR activity.

Diff Parser: Extracts only the added and modified lines for efficient processing.

Static Analyzer: Validates against the rules.yaml standard.

Groq LLM Service: Performs context-aware analysis of the code changes.

Decision Engine: Aggregates scores and applies the final verdict (PASS/FAIL).

GitHub API: Posts comments and sets commit statuses.

Architecture diagram

graph TD

subgraph "External"

GH["GitHub Webhook"]

end

subgraph "Entry & Orchestration (main.py)"

API["Flask Webhook Handler"]

DASH["Dashboard UI"]

end

subgraph "Service Layer (services/)"

GSC["GitHub Service (API Integration)"]

end

subgraph "Review Engine (review/)"

RSO["Review Service (Orchestrator)"]

DP["Diff Parser"]

RC["Rule Checker (Static)"]

DE["Decision Engine (Final Verdict)"]

end

subgraph "AI Agent Layer (agent/)"

LG["LangGraph Orchestrator"]

RCA["RCA Agent (Contextual Analysis)"]

CRA["Code Review Agent (Issue Detection)"]

end

subgraph "Data & Context (data/)"

DB["SQLite (Logging & Stats)"]

RAG["Retriever (Vector Search)"]

end

GH --> API

API --> GSC

GSC --> RSO

%% Review Process

RSO --> DP

RSO --> RC

RSO --> LG

%% AI Flow

LG --> RAG

LG --> RCA

RCA --> CRA

%% Finalization

RC --> DE

LG --> DE

DE --> GSC

DE --> DB

%% Dashboard

DB --> DASH

5. Why We're Better ğŸ†

Built for Speed: leverages Groq's high-speed inference for near-instant reviews.

Configurable: Not a "black box" â€“ you decide exactly what fails a PR.

Integrated: Works seamlessly with existing GitHub workflows (no new tools for devs).

6. The Impact ğŸ“ˆ

70% Reduction in initial review time.

ZERO hardcoded secrets in production.

100% Alignment with organizational coding standards.



ğŸ› ï¸ Tech Stack

Language: Python 3.10+

Framework: Flask

AI Engine: Groq (Llama 3)

Database: SQLite (for stats & logs)

Integration: GitHub API (PyGithub)

UI: Vanilla JS + CSS (Dashboard)